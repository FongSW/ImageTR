{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning Base.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wfXXlXjBaGYO",
        "8V7kWBAmbDIZ",
        "3qipmeoFb_AH",
        "gBC68piHcVa5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfXXlXjBaGYO"
      },
      "source": [
        "## **Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLH7vMQkWLI",
        "outputId": "8360890c-fe58-4c15-af03-db30f845a05f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXAYAWB3Zu7J"
      },
      "source": [
        "# นำเข้า Method สำหรับอ่าน และแสดงผลภาพจาก skimage.io \n",
        "from skimage.io import imread\n",
        "\n",
        "# นำเข้า Library matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# นำเข้า method สำหรับแบ่งข้อมูล Train และ Test Model sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# นำเข้า method สำหรับประเมิณความแม่นยำของ Model จาก sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# นำเข้า Library PyTorch และ modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "# นำเข้า Library Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# นำเข้า Library Numpy\n",
        "import numpy as np\n",
        "\n",
        "# นำเข้า Library OpenCV\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V7kWBAmbDIZ"
      },
      "source": [
        "## **Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7l9qDGubGSB",
        "outputId": "b855c0d9-2373-4ff8-f531-7fe146c492c9"
      },
      "source": [
        "train_img = []\n",
        "train_label = []\n",
        "\n",
        "# นำเข้าข้อมูลรูปภาพที่ใช้ทำการฝึกสอน\n",
        "for floder in tqdm(range(1,7)):\n",
        "  for i in range(1, 21):\n",
        "    impath = '/content/drive/MyDrive/Colab Notebooks/IMG/Tr/' + str(floder) + '/text (' + str(i) + ').bmp'\n",
        "\n",
        "    # อ่านข้อมูลรูปภาพ และแปลงให้เป็นภาพ Gray scale\n",
        "    img = imread(impath, as_gray=True)\n",
        "\n",
        "    # ทำการปรับขนาด Pixel ของภาพ \n",
        "    img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    # แปลง Data type ให้เป็น float32\n",
        "    img = img.astype('float32')\n",
        "\n",
        "    # ปรับค่าของ Pixel ให้อยู่ในขนาด 0-1\n",
        "    img /= 255.0\n",
        "\n",
        "    # ทำการข้อมูลรูปภาพไว้ในตัวแปร train_img\n",
        "    train_img.append(img)\n",
        "\n",
        "    # สร้าง Label ตามจำนวนของ Floder\n",
        "    train_label.append(floder)\n",
        "\n",
        "# ทำการแปลงข้อมูลให้อยู่ใน format ของ numpy เพื่อให้ทำการคำนวณได้เร็วขึ้น\n",
        "train_x = np.array(train_img)\n",
        "train_y = np.array(train_label)\n",
        "\n",
        "# ทำการเช็คขนาดของข้อมูลที่อยู่ใน ตัวแปร train_x, train_y  \n",
        "print(train_x.shape, train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 20.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(120, 128, 128) (120,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qipmeoFb_AH"
      },
      "source": [
        "## **Training & Validating Set Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgf94QJ7TNxZ",
        "outputId": "3efbe2eb-a211-4254-cf5c-3972004ce18c"
      },
      "source": [
        "# ทำการแบ่งข้อมูลสำหรับ Train 90% และ Test 10%\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1)\n",
        "\n",
        "# ทำการเช็คขนาดของข้อมูลที่อยู่ใน ตัวแปร train_x, val_x \n",
        "print(train_x.shape, val_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(108, 128, 128) (12, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BumdVLymb_85",
        "outputId": "b94014b2-0274-46d7-9b25-efc8f701be4a"
      },
      "source": [
        "# converting training images into torch format\n",
        "train_x = train_x.reshape(108, 1, 128, 128)\n",
        "train_x = torch.from_numpy(train_x).to(torch.float32)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y).to(torch.float32)\n",
        "\n",
        "# shape of training data\n",
        "print(train_x.shape, train_y.shape)\n",
        "\n",
        "# converting validation images into torch format\n",
        "val_x = val_x.reshape(12, 1, 128, 128)\n",
        "val_x = torch.from_numpy(val_x).to(torch.float32)\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y).to(torch.float32)\n",
        "\n",
        "# shape of validation data\n",
        "print(val_x.shape, val_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([108, 1, 128, 128]) torch.Size([108])\n",
            "torch.Size([12, 1, 128, 128]) torch.Size([12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNsKPFfxaFMX"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbVVjYT9aQjf"
      },
      "source": [
        "class Net(Module):\n",
        "    def __init__(self): # ก ําหนดโครงสร้ํางใน Constructor\n",
        "\n",
        "      super(Net, self).__init__()\n",
        "      self.cnn_layers = Sequential(\n",
        "        # Defining a 2D convolution layer\n",
        "        Conv2d(1,12,kernel_size=3, stride=1, padding=1),\n",
        "        BatchNorm2d(12),\n",
        "        ReLU(inplace=True),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Defining another 2D convolution layer\n",
        "        Conv2d(12,24,kernel_size=3, stride=1, padding=1),\n",
        "        BatchNorm2d(24),\n",
        "        ReLU(inplace=True),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Defining another 2D convolution layer\n",
        "        Conv2d(24, 36, kernel_size=3, stride=1, padding=1),\n",
        "        BatchNorm2d(36),\n",
        "        ReLU(inplace=True),\n",
        "        MaxPool2d(kernel_size=2, stride=2),\n",
        "      )\n",
        "\n",
        "      self.drop_out = Dropout()\n",
        "      self.fc1 = Linear(36 * 16 * 16, 1000)\n",
        "      self.fc2 = Linear(1000, 500)\n",
        "      self.fc3 = Linear(500, 7)\n",
        "\n",
        "    # Defining how the data flows through these layers when performing the forward pass through the network\n",
        "    def forward(self, x):\n",
        "      x = self.cnn_layers(x)\n",
        "      # convert feature map to vector form\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.drop_out(x)\n",
        "      x = self.fc1(x)\n",
        "      x = self.drop_out(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "# model = Net()\n",
        "# torch.save(model, '/content/drive/MyDrive/Colab Notebooks/IMG/Net.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBC68piHcVa5"
      },
      "source": [
        "## **Defining Learning Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBMarwMTcWYR"
      },
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "\n",
        "# defining the optimizer\n",
        "optimizer = SGD(model.parameters(), lr=0.07, momentum=0.9)\n",
        "\n",
        "# # defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "  criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGRaoWzAgKi9"
      },
      "source": [
        "## **Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP8DIueQgVEp",
        "outputId": "ae18299a-c2fd-40ff-f788-9670256e96df"
      },
      "source": [
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# defining the number of epochs\n",
        "n_epochs = 20\n",
        "# training the model\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "  model.train()\n",
        "  tr_loss = 0\n",
        "\n",
        "  # getting the training set\n",
        "  x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "\n",
        "  # getting the validation set\n",
        "  x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "\n",
        "  # clearing the Gradients of the model parameters\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # prediction for training and validation set\n",
        "  output_train = model(x_train)\n",
        "  output_val = model(x_val)\n",
        "\n",
        "# computing the training and validation loss\n",
        "# we convert the results because they aren't in the good format\n",
        "\n",
        "y_train = y_train.long()\n",
        "y_train = y_train.squeeze_()\n",
        "y_val = y_val.long()\n",
        "y_val = y_val.squeeze_()\n",
        "\n",
        "loss_train = criterion(output_train, y_train)\n",
        "loss_val = criterion(output_val, y_val)\n",
        "train_losses.append(loss_train)\n",
        "val_losses.append(loss_val)\n",
        "\n",
        "# computing the updated weights of all the model parameters\n",
        "loss_train.backward()\n",
        "optimizer.step()\n",
        "tr_loss = loss_train.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:13<00:00,  1.49it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTLgushVBCr"
      },
      "source": [
        "# Saving Entire Model\n",
        "# A common PyTorch convention is to save models\n",
        "# using either a .pt or .pth file extension.\n",
        "# torch.save(model, '/content/drive/MyDrive/Colab Notebooks/IMG/model91.67%.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdiAlCYV-Pe"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKBUiLGtWC1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc6cfda-2813-4786-c28d-2295db39570a"
      },
      "source": [
        "# prediction for validation set\n",
        "# don’t need gradients in test step since the\n",
        "# parameter updates has been done in training\n",
        "# step. Using ‘torch.no_grad()’ in the test and\n",
        "# validation phase yields the faster\n",
        "# inference(speed up computation) and reduced\n",
        "# memory usage(which allows us to use larger\n",
        "# size of batch).\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(val_x)\n",
        "\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# accuracy on validation set\n",
        "print(\"{:.2f} %\".format(round(accuracy_score(val_y, predictions) * 100, 3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.33 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3L6lxq3X3bA"
      },
      "source": [
        "## **Executing Model with Testing Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBzXqBtYX8Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0949317b-4f4f-4779-9163-aa26c2ef1b84"
      },
      "source": [
        "# # loading test images\n",
        "# test_img = []\n",
        "\n",
        "# # Test Image Loader and Feature Extraction\n",
        "# impath = '/content/drive/MyDrive/Colab Notebooks/IMG/Tr/6/text (20).bmp'\n",
        "\n",
        "# # reading the image\n",
        "# img = imread(impath, as_gray=True)\n",
        "\n",
        "# # RESIZE\n",
        "# img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "# # normalizing the pixel values AND converting the type of pixel to float\n",
        "# img = img.astype('float32')\n",
        "# img /= 255.0\n",
        "\n",
        "# # appending the image into the list\n",
        "# test_img.append(img)\n",
        "\n",
        "# # converting the list to numpy array\n",
        "# test_x = np.array(test_img)\n",
        "\n",
        "# # converting training images into torch format\n",
        "# test_x = test_x.reshape(1, 1, 128, 128)\n",
        "# test_x = torch.from_numpy(test_x).to(torch.float32)\n",
        "\n",
        "# # generating predictions for test set\n",
        "# with torch.no_grad():\n",
        "#   #output = model(test_x.cuda())\n",
        "#   output = model(test_x)\n",
        "\n",
        "# softmax = torch.exp(output).cpu()\n",
        "# prob = list(softmax.numpy())\n",
        "# predictions = np.argmax(prob, axis=1)\n",
        "# print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}